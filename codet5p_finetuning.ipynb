{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install all the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/szymon/.local/lib/python3.9/site-packages (4.35.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: filelock in /home/szymon/.local/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/szymon/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/szymon/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/szymon/.local/lib/python3.9/site-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/szymon/.local/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/szymon/.local/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/szymon/.local/lib/python3.9/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: torch in /home/szymon/.local/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/szymon/.local/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/szymon/.local/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/szymon/.local/lib/python3.9/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: networkx in /home/szymon/.local/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/szymon/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/szymon/.local/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/szymon/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/szymon/.local/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/szymon/.local/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /home/szymon/.local/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/szymon/.local/lib/python3.9/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/szymon/.local/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/szymon/.local/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/szymon/.local/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement inspect\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for inspect\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/szymon/.local/lib/python3.9/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (52.0.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/szymon/.local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/szymon/.local/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/szymon/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/szymon/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/szymon/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/szymon/.local/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/szymon/.local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/szymon/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/szymon/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/szymon/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/szymon/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/szymon/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/szymon/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/szymon/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/szymon/.local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: tqdm in /home/szymon/.local/lib/python3.9/site-packages (4.65.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install inspect\n",
    "!pip install tensorflow\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get the data from open-source library TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert\n",
      "@tf_export(\"debugging.Assert\", \"Assert\")\n",
      "@dispatch.add_dispatch_support\n",
      "@tf_should_use.should_use_result\n",
      "def Assert(condition, data, summarize=None, name=None):\n",
      "  \"\"\"Asserts that the given condition is true.\n",
      "\n",
      "  If `condition` evaluates to false, print the list of tensors in `data`.\n",
      "  `summarize` determines how many entries of the tensors to print.\n",
      "\n",
      "  Args:\n",
      "    condition: The condition to evaluate.\n",
      "    data: The tensors to print out when condition is false.\n",
      "    summarize: Print this many entries of each tensor.\n",
      "    name: A name for this operation (optional).\n",
      "\n",
      "  Returns:\n",
      "    assert_op: An `Operation` that, when executed, raises a\n",
      "    `tf.errors.InvalidArgumentError` if `condition` is not true.\n",
      "    @compatibility(eager)\n",
      "    returns None\n",
      "    @end_compatibility\n",
      "\n",
      "  Raises:\n",
      "    @compatibility(TF1)\n",
      "    When in TF V1 mode (that is, outside `tf.function`) Assert needs a control\n",
      "    dependency on the output to ensure the assertion executes:\n",
      "\n",
      "  ```python\n",
      "  # Ensure maximum element of x is smaller or equal to 1\n",
      "  assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\n",
      "  with tf.control_dependencies([assert_op]):\n",
      "    ... code using x ...\n",
      "  ```\n",
      "\n",
      "    @end_compatibility\n",
      "  \"\"\"\n",
      "  if context.executing_eagerly():\n",
      "    if not condition:\n",
      "      xs = ops.convert_n_to_tensor(data)\n",
      "      data_str = [_summarize_eager(x, summarize) for x in xs]\n",
      "      raise errors.InvalidArgumentError(\n",
      "          node_def=None,\n",
      "          op=None,\n",
      "          message=\"Expected '%s' to be true. Summarized data: %s\" %\n",
      "          (condition, \"\\n\".join(data_str)))\n",
      "    return\n",
      "\n",
      "  with ops.name_scope(name, \"Assert\", [condition, data]) as name:\n",
      "    xs = ops.convert_n_to_tensor(data)\n",
      "    if all(x.dtype in {dtypes.string, dtypes.int32} for x in xs):\n",
      "      # As a simple heuristic, we assume that string and int32 are\n",
      "      # on host to avoid the need to use cond. If it is not case,\n",
      "      # we will pay the price copying the tensor to host memory.\n",
      "      return gen_logging_ops._assert(condition, data, summarize, name=\"Assert\")  # pylint: disable=protected-access\n",
      "    else:\n",
      "      condition = ops.convert_to_tensor(condition, name=\"Condition\")\n",
      "\n",
      "      def true_assert():\n",
      "        return gen_logging_ops._assert(  # pylint: disable=protected-access\n",
      "            condition, data, summarize, name=\"Assert\")\n",
      "\n",
      "      guarded_assert = cond.cond(\n",
      "          condition,\n",
      "          gen_control_flow_ops.no_op,\n",
      "          true_assert,\n",
      "          name=\"AssertGuard\")\n",
      "      if context.executing_eagerly():\n",
      "        return\n",
      "      return guarded_assert.op\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import tensorflow\n",
    "\n",
    "functions = inspect.getmembers(tensorflow, inspect.isfunction)\n",
    "method_names = [f[0] for f in functions]\n",
    "code_snippets = [inspect.getsource(f[1]) for f in functions]\n",
    "\n",
    "print(method_names[0])\n",
    "print(code_snippets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_code, eval_code, train_methods, eval_methods = train_test_split(\n",
    "    code_snippets, method_names, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to represent the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, code_snippets, method_names, tokenizer, max_length=128):\n",
    "        self.inputs = code_snippets\n",
    "        self.targets = method_names\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.inputs[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        input_ids = self.tokenizer(\n",
    "            input,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids.squeeze()\n",
    "\n",
    "        target_ids = self.tokenizer(\n",
    "            target,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids.squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": target_ids,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Set up and fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch in eval_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before fine-tuning: 13.898892974853515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:08<00:00,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 4.229760837554932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:08<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.7571238994598388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:55<01:23,  6.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m eval_model(model, eval_loader, device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "checkpoint = \"Salesforce/codet5p-220m\"\n",
    "device = \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "train_dataset = CodeDataset(train_code, train_methods, tokenizer)\n",
    "eval_dataset = CodeDataset(eval_code, eval_methods, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Let's see how our model performs before training\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=True)\n",
    "loss = eval_model(model, eval_loader, device)\n",
    "print(f'loss before fine-tuning: {loss}')\n",
    "\n",
    "for epoch in range(1, 15):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    loss = eval_model(model, eval_loader, device)\n",
    "    print(f\"epoch: {epoch}, loss: {loss}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
